2021-04-06 14:25:07.139 [main] INFO  com.boot.kafka.KafkaApplication - Starting KafkaApplication using Java 1.8.0_131 on LAPTOP-281R0H88 with PID 19496 (D:\project\code\self_util\muti-scaffold\boot-kafka\target\classes started by 月月 in D:\project\code\self_util\muti-scaffold)
2021-04-06 14:25:07.148 [main] INFO  com.boot.kafka.KafkaApplication - The following profiles are active: dev,kafka,business
2021-04-06 14:25:08.434 [main] INFO  o.s.boot.web.embedded.tomcat.TomcatWebServer - Tomcat initialized with port(s): 9200 (http)
2021-04-06 14:25:08.444 [main] INFO  org.apache.coyote.http11.Http11NioProtocol - Initializing ProtocolHandler ["http-nio-9200"]
2021-04-06 14:25:08.445 [main] INFO  org.apache.catalina.core.StandardService - Starting service [Tomcat]
2021-04-06 14:25:08.447 [main] INFO  org.apache.catalina.core.StandardEngine - Starting Servlet engine: [Apache Tomcat/9.0.43]
2021-04-06 14:25:08.548 [main] INFO  o.a.c.core.ContainerBase.[Tomcat].[localhost].[/] - Initializing Spring embedded WebApplicationContext
2021-04-06 14:25:08.548 [main] INFO  o.s.b.w.s.c.ServletWebServerApplicationContext - Root WebApplicationContext: initialization completed in 1350 ms
2021-04-06 14:25:08.604 [main] INFO  com.boot.kafka.common.GlobalObject - kafka配置读取成功
2021-04-06 14:25:08.641 [main] INFO  org.quartz.impl.StdSchedulerFactory - Using default implementation for ThreadExecutor
2021-04-06 14:25:08.657 [main] INFO  org.quartz.core.SchedulerSignalerImpl - Initialized Scheduler Signaller of type: class org.quartz.core.SchedulerSignalerImpl
2021-04-06 14:25:08.657 [main] INFO  org.quartz.core.QuartzScheduler - Quartz Scheduler v.2.3.2 created.
2021-04-06 14:25:08.658 [main] INFO  org.quartz.simpl.RAMJobStore - RAMJobStore initialized.
2021-04-06 14:25:08.659 [main] INFO  org.quartz.core.QuartzScheduler - Scheduler meta-data: Quartz Scheduler (v2.3.2) 'quartzScheduler' with instanceId 'NON_CLUSTERED'
  Scheduler class: 'org.quartz.core.QuartzScheduler' - running locally.
  NOT STARTED.
  Currently in standby mode.
  Number of jobs executed: 0
  Using thread pool 'org.quartz.simpl.SimpleThreadPool' - with 10 threads.
  Using job-store 'org.quartz.simpl.RAMJobStore' - which does not support persistence. and is not clustered.

2021-04-06 14:25:08.659 [main] INFO  org.quartz.impl.StdSchedulerFactory - Quartz scheduler 'quartzScheduler' initialized from an externally provided properties instance.
2021-04-06 14:25:08.659 [main] INFO  org.quartz.impl.StdSchedulerFactory - Quartz scheduler version: 2.3.2
2021-04-06 14:25:08.659 [main] INFO  org.quartz.core.QuartzScheduler - JobFactory set to: org.springframework.scheduling.quartz.SpringBeanJobFactory@3d40a3b4
2021-04-06 14:25:08.660 [main] INFO  org.quartz.core.QuartzScheduler - Scheduler quartzScheduler_$_NON_CLUSTERED started.
2021-04-06 14:25:08.660 [main] INFO  com.boot.kafka.config.task.SchedulerConfig - 调度器启动成功
2021-04-06 14:25:08.668 [main] INFO  com.boot.kafka.config.task.SchedulerConfig - 流任务初始化成功
2021-04-06 14:25:08.679 [quartzScheduler_Worker-1] INFO  com.boot.kafka.config.task.StreamJob - 开始启动kafka的流式操作
2021-04-06 14:25:08.702 [quartzScheduler_Worker-1] INFO  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [172.17.112.123:19192]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 3
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2021-04-06 14:25:08.721 [quartzScheduler_Worker-1] INFO  org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-1] Instantiated an idempotent producer.
2021-04-06 14:25:08.776 [quartzScheduler_Worker-1] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.0.0
2021-04-06 14:25:08.776 [quartzScheduler_Worker-1] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : 3402a8361b734732
2021-04-06 14:25:08.778 [quartzScheduler_Worker-1] INFO  com.boot.kafka.util.KafkaUtil - 等幂模式Kafka生产者初始化成功
2021-04-06 14:25:08.798 [main] INFO  o.s.scheduling.quartz.SchedulerFactoryBean - Shutting down Quartz Scheduler
2021-04-06 14:25:08.798 [main] INFO  org.quartz.core.QuartzScheduler - Scheduler quartzScheduler_$_NON_CLUSTERED shutting down.
2021-04-06 14:25:08.798 [main] INFO  org.quartz.core.QuartzScheduler - Scheduler quartzScheduler_$_NON_CLUSTERED paused.
2021-04-06 14:25:08.799 [main] INFO  org.quartz.core.QuartzScheduler - Scheduler quartzScheduler_$_NON_CLUSTERED shutdown complete.
2021-04-06 14:25:08.804 [main] INFO  org.apache.catalina.core.StandardService - Stopping service [Tomcat]
2021-04-06 14:25:08.816 [main] INFO  o.s.b.a.l.ConditionEvaluationReportLoggingListener - 

Error starting ApplicationContext. To display the conditions report re-run your application with 'debug' enabled.
2021-04-06 14:25:08.991 [kafka-producer-network-thread | producer-1] INFO  o.a.k.c.producer.internals.TransactionManager - [Producer clientId=producer-1] ProducerId set to 3018 with epoch 0
2021-04-06 14:26:46.343 [main] INFO  com.boot.kafka.KafkaApplication - Starting KafkaApplication using Java 1.8.0_131 on LAPTOP-281R0H88 with PID 23712 (D:\project\code\self_util\muti-scaffold\boot-kafka\target\classes started by 月月 in D:\project\code\self_util\muti-scaffold)
2021-04-06 14:26:46.347 [main] INFO  com.boot.kafka.KafkaApplication - The following profiles are active: dev,kafka,business
2021-04-06 14:26:47.577 [main] INFO  o.s.boot.web.embedded.tomcat.TomcatWebServer - Tomcat initialized with port(s): 9200 (http)
2021-04-06 14:26:47.588 [main] INFO  org.apache.coyote.http11.Http11NioProtocol - Initializing ProtocolHandler ["http-nio-9200"]
2021-04-06 14:26:47.589 [main] INFO  org.apache.catalina.core.StandardService - Starting service [Tomcat]
2021-04-06 14:26:47.590 [main] INFO  org.apache.catalina.core.StandardEngine - Starting Servlet engine: [Apache Tomcat/9.0.43]
2021-04-06 14:26:47.683 [main] INFO  o.a.c.core.ContainerBase.[Tomcat].[localhost].[/] - Initializing Spring embedded WebApplicationContext
2021-04-06 14:26:47.683 [main] INFO  o.s.b.w.s.c.ServletWebServerApplicationContext - Root WebApplicationContext: initialization completed in 1286 ms
2021-04-06 14:26:47.739 [main] INFO  com.boot.kafka.common.GlobalObject - kafka配置读取成功
2021-04-06 14:26:47.775 [main] INFO  org.quartz.impl.StdSchedulerFactory - Using default implementation for ThreadExecutor
2021-04-06 14:26:47.789 [main] INFO  org.quartz.core.SchedulerSignalerImpl - Initialized Scheduler Signaller of type: class org.quartz.core.SchedulerSignalerImpl
2021-04-06 14:26:47.789 [main] INFO  org.quartz.core.QuartzScheduler - Quartz Scheduler v.2.3.2 created.
2021-04-06 14:26:47.790 [main] INFO  org.quartz.simpl.RAMJobStore - RAMJobStore initialized.
2021-04-06 14:26:47.791 [main] INFO  org.quartz.core.QuartzScheduler - Scheduler meta-data: Quartz Scheduler (v2.3.2) 'quartzScheduler' with instanceId 'NON_CLUSTERED'
  Scheduler class: 'org.quartz.core.QuartzScheduler' - running locally.
  NOT STARTED.
  Currently in standby mode.
  Number of jobs executed: 0
  Using thread pool 'org.quartz.simpl.SimpleThreadPool' - with 10 threads.
  Using job-store 'org.quartz.simpl.RAMJobStore' - which does not support persistence. and is not clustered.

2021-04-06 14:26:47.791 [main] INFO  org.quartz.impl.StdSchedulerFactory - Quartz scheduler 'quartzScheduler' initialized from an externally provided properties instance.
2021-04-06 14:26:47.791 [main] INFO  org.quartz.impl.StdSchedulerFactory - Quartz scheduler version: 2.3.2
2021-04-06 14:26:47.792 [main] INFO  org.quartz.core.QuartzScheduler - JobFactory set to: org.springframework.scheduling.quartz.SpringBeanJobFactory@9687f55
2021-04-06 14:26:47.792 [main] INFO  org.quartz.core.QuartzScheduler - Scheduler quartzScheduler_$_NON_CLUSTERED started.
2021-04-06 14:26:47.792 [main] INFO  com.boot.kafka.config.task.SchedulerConfig - 调度器启动成功
2021-04-06 14:26:47.798 [main] INFO  com.boot.kafka.config.task.SchedulerConfig - 流任务初始化成功
2021-04-06 14:26:47.809 [quartzScheduler_Worker-1] INFO  com.boot.kafka.config.task.StreamJob - 开始启动kafka的流式操作
2021-04-06 14:26:47.839 [quartzScheduler_Worker-1] INFO  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [172.17.112.123:19192]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 3
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2021-04-06 14:26:47.857 [quartzScheduler_Worker-1] INFO  org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-1] Instantiated an idempotent producer.
2021-04-06 14:26:47.908 [quartzScheduler_Worker-1] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.0.0
2021-04-06 14:26:47.908 [quartzScheduler_Worker-1] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : 3402a8361b734732
2021-04-06 14:26:47.910 [quartzScheduler_Worker-1] INFO  com.boot.kafka.util.KafkaUtil - 等幂模式Kafka生产者初始化成功
2021-04-06 14:26:57.623 [main] INFO  o.s.scheduling.quartz.SchedulerFactoryBean - Shutting down Quartz Scheduler
2021-04-06 14:26:57.623 [main] INFO  org.quartz.core.QuartzScheduler - Scheduler quartzScheduler_$_NON_CLUSTERED shutting down.
2021-04-06 14:26:57.623 [main] INFO  org.quartz.core.QuartzScheduler - Scheduler quartzScheduler_$_NON_CLUSTERED paused.
2021-04-06 14:26:57.623 [main] INFO  org.quartz.core.QuartzScheduler - Scheduler quartzScheduler_$_NON_CLUSTERED shutdown complete.
2021-04-06 14:26:57.626 [main] INFO  org.apache.catalina.core.StandardService - Stopping service [Tomcat]
2021-04-06 14:26:57.637 [main] INFO  o.s.b.a.l.ConditionEvaluationReportLoggingListener - 

Error starting ApplicationContext. To display the conditions report re-run your application with 'debug' enabled.
2021-04-06 14:26:57.760 [kafka-producer-network-thread | producer-1] INFO  o.a.k.c.producer.internals.TransactionManager - [Producer clientId=producer-1] ProducerId set to 3019 with epoch 0
2021-04-06 14:27:28.105 [main] INFO  com.boot.kafka.KafkaApplication - Starting KafkaApplication using Java 1.8.0_131 on LAPTOP-281R0H88 with PID 11968 (D:\project\code\self_util\muti-scaffold\boot-kafka\target\classes started by 月月 in D:\project\code\self_util\muti-scaffold)
2021-04-06 14:27:28.110 [main] INFO  com.boot.kafka.KafkaApplication - The following profiles are active: dev,kafka,business
2021-04-06 14:27:29.331 [main] INFO  o.s.boot.web.embedded.tomcat.TomcatWebServer - Tomcat initialized with port(s): 9200 (http)
2021-04-06 14:27:29.339 [main] INFO  org.apache.coyote.http11.Http11NioProtocol - Initializing ProtocolHandler ["http-nio-9200"]
2021-04-06 14:27:29.340 [main] INFO  org.apache.catalina.core.StandardService - Starting service [Tomcat]
2021-04-06 14:27:29.340 [main] INFO  org.apache.catalina.core.StandardEngine - Starting Servlet engine: [Apache Tomcat/9.0.43]
2021-04-06 14:27:29.434 [main] INFO  o.a.c.core.ContainerBase.[Tomcat].[localhost].[/] - Initializing Spring embedded WebApplicationContext
2021-04-06 14:27:29.434 [main] INFO  o.s.b.w.s.c.ServletWebServerApplicationContext - Root WebApplicationContext: initialization completed in 1272 ms
2021-04-06 14:27:29.491 [main] INFO  com.boot.kafka.common.GlobalObject - kafka配置读取成功
2021-04-06 14:27:29.528 [main] INFO  org.quartz.impl.StdSchedulerFactory - Using default implementation for ThreadExecutor
2021-04-06 14:27:29.541 [main] INFO  org.quartz.core.SchedulerSignalerImpl - Initialized Scheduler Signaller of type: class org.quartz.core.SchedulerSignalerImpl
2021-04-06 14:27:29.542 [main] INFO  org.quartz.core.QuartzScheduler - Quartz Scheduler v.2.3.2 created.
2021-04-06 14:27:29.543 [main] INFO  org.quartz.simpl.RAMJobStore - RAMJobStore initialized.
2021-04-06 14:27:29.544 [main] INFO  org.quartz.core.QuartzScheduler - Scheduler meta-data: Quartz Scheduler (v2.3.2) 'quartzScheduler' with instanceId 'NON_CLUSTERED'
  Scheduler class: 'org.quartz.core.QuartzScheduler' - running locally.
  NOT STARTED.
  Currently in standby mode.
  Number of jobs executed: 0
  Using thread pool 'org.quartz.simpl.SimpleThreadPool' - with 10 threads.
  Using job-store 'org.quartz.simpl.RAMJobStore' - which does not support persistence. and is not clustered.

2021-04-06 14:27:29.544 [main] INFO  org.quartz.impl.StdSchedulerFactory - Quartz scheduler 'quartzScheduler' initialized from an externally provided properties instance.
2021-04-06 14:27:29.544 [main] INFO  org.quartz.impl.StdSchedulerFactory - Quartz scheduler version: 2.3.2
2021-04-06 14:27:29.544 [main] INFO  org.quartz.core.QuartzScheduler - JobFactory set to: org.springframework.scheduling.quartz.SpringBeanJobFactory@22bf9122
2021-04-06 14:27:29.545 [main] INFO  org.quartz.core.QuartzScheduler - Scheduler quartzScheduler_$_NON_CLUSTERED started.
2021-04-06 14:27:29.545 [main] INFO  com.boot.kafka.config.task.SchedulerConfig - 调度器启动成功
2021-04-06 14:27:29.551 [main] INFO  com.boot.kafka.config.task.SchedulerConfig - 流任务初始化成功
2021-04-06 14:27:29.562 [quartzScheduler_Worker-1] INFO  com.boot.kafka.config.task.StreamJob - 开始启动kafka的流式操作
2021-04-06 14:27:29.583 [quartzScheduler_Worker-1] INFO  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [172.17.112.123:19192]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 3
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2021-04-06 14:27:29.602 [quartzScheduler_Worker-1] INFO  org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-1] Instantiated an idempotent producer.
2021-04-06 14:27:29.653 [quartzScheduler_Worker-1] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.0.0
2021-04-06 14:27:29.654 [quartzScheduler_Worker-1] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : 3402a8361b734732
2021-04-06 14:27:29.655 [quartzScheduler_Worker-1] INFO  com.boot.kafka.util.KafkaUtil - 等幂模式Kafka生产者初始化成功
2021-04-06 14:27:29.679 [quartzScheduler_Worker-1] INFO  org.apache.kafka.streams.StreamsConfig - StreamsConfig values: 
	application.id = test-ath
	application.server = 
	bootstrap.servers = [172.17.112.123:19192]
	buffered.records.per.partition = 1000
	cache.max.bytes.buffering = 10485760
	client.id = 
	commit.interval.ms = 30000
	connections.max.idle.ms = 540000
	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
	default.key.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
	default.value.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	num.standby.replicas = 0
	num.stream.threads = 1
	partition.grouper = class org.apache.kafka.streams.processor.DefaultPartitionGrouper
	poll.ms = 100
	processing.guarantee = at_least_once
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	replication.factor = 1
	request.timeout.ms = 40000
	retries = 0
	retry.backoff.ms = 100
	rocksdb.config.setter = null
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	state.cleanup.delay.ms = 600000
	state.dir = /tmp/kafka-streams
	topology.optimization = none
	upgrade.from = null
	windowstore.changelog.additional.retention.ms = 86400000

2021-04-06 14:27:29.694 [quartzScheduler_Worker-1] INFO  org.apache.kafka.clients.admin.AdminClientConfig - AdminClientConfig values: 
	bootstrap.servers = [172.17.112.123:19192]
	client.id = test-ath-40356c43-f270-46d5-bf62-b3496e1f98f2-admin
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2021-04-06 14:27:29.701 [quartzScheduler_Worker-1] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.0.0
2021-04-06 14:27:29.701 [quartzScheduler_Worker-1] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : 3402a8361b734732
2021-04-06 14:27:29.702 [quartzScheduler_Worker-1] INFO  o.a.kafka.streams.processor.internals.StreamThread - stream-thread [test-ath-40356c43-f270-46d5-bf62-b3496e1f98f2-StreamThread-1] Creating restore consumer client
2021-04-06 14:27:29.705 [quartzScheduler_Worker-1] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = none
	bootstrap.servers = [172.17.112.123:19192]
	check.crcs = true
	client.id = test-ath-40356c43-f270-46d5-bf62-b3496e1f98f2-StreamThread-1-restore-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 2147483647
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2021-04-06 14:27:29.725 [quartzScheduler_Worker-1] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.0.0
2021-04-06 14:27:29.725 [quartzScheduler_Worker-1] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : 3402a8361b734732
2021-04-06 14:27:29.726 [quartzScheduler_Worker-1] INFO  o.a.kafka.streams.processor.internals.StreamThread - stream-thread [test-ath-40356c43-f270-46d5-bf62-b3496e1f98f2-StreamThread-1] Creating shared producer client
2021-04-06 14:27:29.727 [quartzScheduler_Worker-1] INFO  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [172.17.112.123:19192]
	buffer.memory = 33554432
	client.id = test-ath-40356c43-f270-46d5-bf62-b3496e1f98f2-StreamThread-1-producer
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 100
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 10
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2021-04-06 14:27:29.731 [quartzScheduler_Worker-1] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.0.0
2021-04-06 14:27:29.731 [quartzScheduler_Worker-1] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : 3402a8361b734732
2021-04-06 14:27:29.739 [quartzScheduler_Worker-1] INFO  o.a.kafka.streams.processor.internals.StreamThread - stream-thread [test-ath-40356c43-f270-46d5-bf62-b3496e1f98f2-StreamThread-1] Creating consumer client
2021-04-06 14:27:29.740 [quartzScheduler_Worker-1] INFO  org.apache.kafka.clients.admin.AdminClientConfig - AdminClientConfig values: 
	bootstrap.servers = [172.17.112.123:19192]
	client.id = 
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2021-04-06 14:27:29.741 [quartzScheduler_Worker-1] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [172.17.112.123:19192]
	check.crcs = true
	client.id = test-ath-40356c43-f270-46d5-bf62-b3496e1f98f2-StreamThread-1-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-ath
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 2147483647
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2021-04-06 14:27:29.744 [quartzScheduler_Worker-1] INFO  org.apache.kafka.streams.StreamsConfig - StreamsConfig values: 
	application.id = test-ath
	application.server = 
	bootstrap.servers = [172.17.112.123:19192]
	buffered.records.per.partition = 1000
	cache.max.bytes.buffering = 10485760
	client.id = test-ath-40356c43-f270-46d5-bf62-b3496e1f98f2-StreamThread-1-consumer
	commit.interval.ms = 30000
	connections.max.idle.ms = 540000
	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
	default.key.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
	default.value.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	num.standby.replicas = 0
	num.stream.threads = 1
	partition.grouper = class org.apache.kafka.streams.processor.DefaultPartitionGrouper
	poll.ms = 100
	processing.guarantee = at_least_once
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	replication.factor = 1
	request.timeout.ms = 40000
	retries = 0
	retry.backoff.ms = 100
	rocksdb.config.setter = null
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	state.cleanup.delay.ms = 600000
	state.dir = /tmp/kafka-streams
	topology.optimization = none
	upgrade.from = null
	windowstore.changelog.additional.retention.ms = 86400000

2021-04-06 14:27:29.745 [quartzScheduler_Worker-1] INFO  org.apache.kafka.clients.admin.AdminClientConfig - AdminClientConfig values: 
	bootstrap.servers = [172.17.112.123:19192]
	client.id = dummy-admin
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2021-04-06 14:27:29.748 [quartzScheduler_Worker-1] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.0.0
2021-04-06 14:27:29.749 [quartzScheduler_Worker-1] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : 3402a8361b734732
2021-04-06 14:27:29.754 [test-ath-40356c43-f270-46d5-bf62-b3496e1f98f2-StreamThread-1] INFO  o.a.kafka.streams.processor.internals.StreamThread - stream-thread [test-ath-40356c43-f270-46d5-bf62-b3496e1f98f2-StreamThread-1] Starting
2021-04-06 14:27:29.799 [test-ath-40356c43-f270-46d5-bf62-b3496e1f98f2-StreamThread-1] INFO  o.a.kafka.streams.processor.internals.StreamThread - stream-thread [test-ath-40356c43-f270-46d5-bf62-b3496e1f98f2-StreamThread-1] State transition from CREATED to RUNNING
2021-04-06 14:27:29.805 [quartzScheduler_Worker-1] INFO  org.apache.kafka.streams.KafkaStreams - stream-client [test-ath-40356c43-f270-46d5-bf62-b3496e1f98f2] Started Streams client
2021-04-06 14:27:29.840 [kafka-producer-network-thread | producer-1] INFO  o.a.k.c.producer.internals.TransactionManager - [Producer clientId=producer-1] ProducerId set to 3020 with epoch 0
2021-04-06 14:27:29.845 [test-ath-40356c43-f270-46d5-bf62-b3496e1f98f2-StreamThread-1] INFO  org.apache.kafka.clients.Metadata - Cluster ID: cseuN2TaSe27oN-yqROAFw
2021-04-06 14:27:29.845 [test-ath-40356c43-f270-46d5-bf62-b3496e1f98f2-StreamThread-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=test-ath-40356c43-f270-46d5-bf62-b3496e1f98f2-StreamThread-1-consumer, groupId=test-ath] Discovered group coordinator 172.17.112.123:19192 (id: 2147483647 rack: null)
2021-04-06 14:27:29.847 [test-ath-40356c43-f270-46d5-bf62-b3496e1f98f2-StreamThread-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=test-ath-40356c43-f270-46d5-bf62-b3496e1f98f2-StreamThread-1-consumer, groupId=test-ath] Revoking previously assigned partitions []
2021-04-06 14:27:29.847 [test-ath-40356c43-f270-46d5-bf62-b3496e1f98f2-StreamThread-1] INFO  o.a.kafka.streams.processor.internals.StreamThread - stream-thread [test-ath-40356c43-f270-46d5-bf62-b3496e1f98f2-StreamThread-1] State transition from RUNNING to PARTITIONS_REVOKED
2021-04-06 14:27:29.847 [test-ath-40356c43-f270-46d5-bf62-b3496e1f98f2-StreamThread-1] INFO  org.apache.kafka.streams.KafkaStreams - stream-client [test-ath-40356c43-f270-46d5-bf62-b3496e1f98f2] State transition from RUNNING to REBALANCING
2021-04-06 14:27:29.848 [test-ath-40356c43-f270-46d5-bf62-b3496e1f98f2-StreamThread-1] INFO  o.a.kafka.streams.processor.internals.StreamThread - stream-thread [test-ath-40356c43-f270-46d5-bf62-b3496e1f98f2-StreamThread-1] partition revocation took 1 ms.
	suspended active tasks: []
	suspended standby tasks: []
2021-04-06 14:27:29.848 [test-ath-40356c43-f270-46d5-bf62-b3496e1f98f2-StreamThread-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=test-ath-40356c43-f270-46d5-bf62-b3496e1f98f2-StreamThread-1-consumer, groupId=test-ath] (Re-)joining group
2021-04-06 14:27:29.872 [test-ath-40356c43-f270-46d5-bf62-b3496e1f98f2-StreamThread-1] INFO  o.a.k.s.p.internals.StreamsPartitionAssignor - stream-thread [test-ath-40356c43-f270-46d5-bf62-b3496e1f98f2-StreamThread-1-consumer] Assigned tasks to clients as {40356c43-f270-46d5-bf62-b3496e1f98f2=[activeTasks: ([0_0, 0_1, 0_2, 0_3, 0_4, 0_5, 0_6, 0_7, 0_8, 0_9]) standbyTasks: ([]) assignedTasks: ([0_0, 0_1, 0_2, 0_3, 0_4, 0_5, 0_6, 0_7, 0_8, 0_9]) prevActiveTasks: ([]) prevStandbyTasks: ([]) prevAssignedTasks: ([]) capacity: 1]}.
2021-04-06 14:27:29.882 [test-ath-40356c43-f270-46d5-bf62-b3496e1f98f2-StreamThread-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=test-ath-40356c43-f270-46d5-bf62-b3496e1f98f2-StreamThread-1-consumer, groupId=test-ath] Successfully joined group with generation 1
2021-04-06 14:27:29.884 [test-ath-40356c43-f270-46d5-bf62-b3496e1f98f2-StreamThread-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=test-ath-40356c43-f270-46d5-bf62-b3496e1f98f2-StreamThread-1-consumer, groupId=test-ath] Setting newly assigned partitions [wiscom.test-0, wiscom.test-1, wiscom.test-6, wiscom.test-7, wiscom.test-8, wiscom.test-9, wiscom.test-2, wiscom.test-3, wiscom.test-4, wiscom.test-5]
2021-04-06 14:27:29.885 [test-ath-40356c43-f270-46d5-bf62-b3496e1f98f2-StreamThread-1] INFO  o.a.kafka.streams.processor.internals.StreamThread - stream-thread [test-ath-40356c43-f270-46d5-bf62-b3496e1f98f2-StreamThread-1] State transition from PARTITIONS_REVOKED to PARTITIONS_ASSIGNED
2021-04-06 14:27:29.908 [test-ath-40356c43-f270-46d5-bf62-b3496e1f98f2-StreamThread-1] INFO  o.a.kafka.streams.processor.internals.StreamThread - stream-thread [test-ath-40356c43-f270-46d5-bf62-b3496e1f98f2-StreamThread-1] partition assignment took 23 ms.
	current active tasks: [0_0, 0_1, 0_2, 0_3, 0_4, 0_5, 0_6, 0_7, 0_8, 0_9]
	current standby tasks: []
	previous active tasks: []

2021-04-06 14:27:29.928 [test-ath-40356c43-f270-46d5-bf62-b3496e1f98f2-StreamThread-1] INFO  o.a.kafka.streams.processor.internals.StreamThread - stream-thread [test-ath-40356c43-f270-46d5-bf62-b3496e1f98f2-StreamThread-1] State transition from PARTITIONS_ASSIGNED to RUNNING
2021-04-06 14:27:29.929 [test-ath-40356c43-f270-46d5-bf62-b3496e1f98f2-StreamThread-1] INFO  org.apache.kafka.streams.KafkaStreams - stream-client [test-ath-40356c43-f270-46d5-bf62-b3496e1f98f2] State transition from REBALANCING to RUNNING
2021-04-06 14:27:29.947 [test-ath-40356c43-f270-46d5-bf62-b3496e1f98f2-StreamThread-1] INFO  o.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=test-ath-40356c43-f270-46d5-bf62-b3496e1f98f2-StreamThread-1-consumer, groupId=test-ath] Resetting offset for partition wiscom.test-0 to offset 2.
2021-04-06 14:27:29.947 [test-ath-40356c43-f270-46d5-bf62-b3496e1f98f2-StreamThread-1] INFO  o.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=test-ath-40356c43-f270-46d5-bf62-b3496e1f98f2-StreamThread-1-consumer, groupId=test-ath] Resetting offset for partition wiscom.test-1 to offset 0.
2021-04-06 14:27:29.947 [test-ath-40356c43-f270-46d5-bf62-b3496e1f98f2-StreamThread-1] INFO  o.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=test-ath-40356c43-f270-46d5-bf62-b3496e1f98f2-StreamThread-1-consumer, groupId=test-ath] Resetting offset for partition wiscom.test-6 to offset 0.
2021-04-06 14:27:29.947 [test-ath-40356c43-f270-46d5-bf62-b3496e1f98f2-StreamThread-1] INFO  o.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=test-ath-40356c43-f270-46d5-bf62-b3496e1f98f2-StreamThread-1-consumer, groupId=test-ath] Resetting offset for partition wiscom.test-7 to offset 0.
2021-04-06 14:27:29.947 [test-ath-40356c43-f270-46d5-bf62-b3496e1f98f2-StreamThread-1] INFO  o.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=test-ath-40356c43-f270-46d5-bf62-b3496e1f98f2-StreamThread-1-consumer, groupId=test-ath] Resetting offset for partition wiscom.test-8 to offset 0.
2021-04-06 14:27:29.948 [test-ath-40356c43-f270-46d5-bf62-b3496e1f98f2-StreamThread-1] INFO  o.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=test-ath-40356c43-f270-46d5-bf62-b3496e1f98f2-StreamThread-1-consumer, groupId=test-ath] Resetting offset for partition wiscom.test-9 to offset 1.
2021-04-06 14:27:29.948 [test-ath-40356c43-f270-46d5-bf62-b3496e1f98f2-StreamThread-1] INFO  o.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=test-ath-40356c43-f270-46d5-bf62-b3496e1f98f2-StreamThread-1-consumer, groupId=test-ath] Resetting offset for partition wiscom.test-2 to offset 1.
2021-04-06 14:27:29.948 [test-ath-40356c43-f270-46d5-bf62-b3496e1f98f2-StreamThread-1] INFO  o.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=test-ath-40356c43-f270-46d5-bf62-b3496e1f98f2-StreamThread-1-consumer, groupId=test-ath] Resetting offset for partition wiscom.test-3 to offset 0.
2021-04-06 14:27:29.948 [test-ath-40356c43-f270-46d5-bf62-b3496e1f98f2-StreamThread-1] INFO  o.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=test-ath-40356c43-f270-46d5-bf62-b3496e1f98f2-StreamThread-1-consumer, groupId=test-ath] Resetting offset for partition wiscom.test-4 to offset 0.
2021-04-06 14:27:29.948 [test-ath-40356c43-f270-46d5-bf62-b3496e1f98f2-StreamThread-1] INFO  o.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=test-ath-40356c43-f270-46d5-bf62-b3496e1f98f2-StreamThread-1-consumer, groupId=test-ath] Resetting offset for partition wiscom.test-5 to offset 2.
2021-04-06 14:27:30.254 [main] INFO  o.s.scheduling.concurrent.ThreadPoolTaskExecutor - Initializing ExecutorService 'applicationTaskExecutor'
2021-04-06 14:27:30.426 [main] INFO  org.apache.coyote.http11.Http11NioProtocol - Starting ProtocolHandler ["http-nio-9200"]
2021-04-06 14:27:30.438 [main] INFO  o.s.boot.web.embedded.tomcat.TomcatWebServer - Tomcat started on port(s): 9200 (http) with context path ''
2021-04-06 14:27:30.658 [main] INFO  com.boot.kafka.KafkaApplication - Started KafkaApplication in 3.1 seconds (JVM running for 4.464)
2021-04-06 14:27:39.871 [http-nio-9200-exec-1] INFO  o.a.c.core.ContainerBase.[Tomcat].[localhost].[/] - Initializing Spring DispatcherServlet 'dispatcherServlet'
2021-04-06 14:27:39.871 [http-nio-9200-exec-1] INFO  org.springframework.web.servlet.DispatcherServlet - Initializing Servlet 'dispatcherServlet'
2021-04-06 14:27:39.873 [http-nio-9200-exec-1] INFO  org.springframework.web.servlet.DispatcherServlet - Completed initialization in 2 ms
2021-04-06 14:27:46.739 [kafka-producer-network-thread | producer-1] INFO  org.apache.kafka.clients.Metadata - Cluster ID: cseuN2TaSe27oN-yqROAFw
2021-04-06 14:27:46.766 [http-nio-9200-exec-2] INFO  com.boot.kafka.dao.ProducerDao - wiscom.test-7@0
2021-04-06 14:27:46.781 [kafka-producer-network-thread | test-ath-40356c43-f270-46d5-bf62-b3496e1f98f2-StreamThread-1-producer] INFO  org.apache.kafka.clients.Metadata - Cluster ID: cseuN2TaSe27oN-yqROAFw
2021-04-06 14:27:59.549 [quartzScheduler_Worker-2] INFO  com.boot.kafka.config.task.StreamJob - 开始启动kafka的流式操作
2021-04-06 14:27:59.550 [quartzScheduler_Worker-2] INFO  org.apache.kafka.streams.KafkaStreams - stream-client [test-ath-40356c43-f270-46d5-bf62-b3496e1f98f2] State transition from RUNNING to PENDING_SHUTDOWN
2021-04-06 14:27:59.552 [kafka-streams-close-thread] INFO  o.a.kafka.streams.processor.internals.StreamThread - stream-thread [test-ath-40356c43-f270-46d5-bf62-b3496e1f98f2-StreamThread-1] Informed to shut down
2021-04-06 14:27:59.552 [kafka-streams-close-thread] INFO  o.a.kafka.streams.processor.internals.StreamThread - stream-thread [test-ath-40356c43-f270-46d5-bf62-b3496e1f98f2-StreamThread-1] State transition from RUNNING to PENDING_SHUTDOWN
2021-04-06 14:28:07.338 [SpringContextShutdownHook] INFO  org.quartz.core.QuartzScheduler - Scheduler quartzScheduler_$_NON_CLUSTERED paused.
2021-04-06 14:29:44.419 [main] INFO  com.boot.kafka.KafkaApplication - Starting KafkaApplication using Java 1.8.0_131 on LAPTOP-281R0H88 with PID 11108 (D:\project\code\self_util\muti-scaffold\boot-kafka\target\classes started by 月月 in D:\project\code\self_util\muti-scaffold)
2021-04-06 14:29:44.423 [main] INFO  com.boot.kafka.KafkaApplication - The following profiles are active: dev,kafka,business
2021-04-06 14:29:45.738 [main] INFO  o.s.boot.web.embedded.tomcat.TomcatWebServer - Tomcat initialized with port(s): 9200 (http)
2021-04-06 14:29:45.747 [main] INFO  org.apache.coyote.http11.Http11NioProtocol - Initializing ProtocolHandler ["http-nio-9200"]
2021-04-06 14:29:45.748 [main] INFO  org.apache.catalina.core.StandardService - Starting service [Tomcat]
2021-04-06 14:29:45.748 [main] INFO  org.apache.catalina.core.StandardEngine - Starting Servlet engine: [Apache Tomcat/9.0.43]
2021-04-06 14:29:45.847 [main] INFO  o.a.c.core.ContainerBase.[Tomcat].[localhost].[/] - Initializing Spring embedded WebApplicationContext
2021-04-06 14:29:45.848 [main] INFO  o.s.b.w.s.c.ServletWebServerApplicationContext - Root WebApplicationContext: initialization completed in 1367 ms
2021-04-06 14:29:45.905 [main] INFO  com.boot.kafka.common.GlobalObject - kafka配置读取成功
2021-04-06 14:29:45.942 [main] INFO  org.quartz.impl.StdSchedulerFactory - Using default implementation for ThreadExecutor
2021-04-06 14:29:45.956 [main] INFO  org.quartz.core.SchedulerSignalerImpl - Initialized Scheduler Signaller of type: class org.quartz.core.SchedulerSignalerImpl
2021-04-06 14:29:45.956 [main] INFO  org.quartz.core.QuartzScheduler - Quartz Scheduler v.2.3.2 created.
2021-04-06 14:29:45.957 [main] INFO  org.quartz.simpl.RAMJobStore - RAMJobStore initialized.
2021-04-06 14:29:45.958 [main] INFO  org.quartz.core.QuartzScheduler - Scheduler meta-data: Quartz Scheduler (v2.3.2) 'quartzScheduler' with instanceId 'NON_CLUSTERED'
  Scheduler class: 'org.quartz.core.QuartzScheduler' - running locally.
  NOT STARTED.
  Currently in standby mode.
  Number of jobs executed: 0
  Using thread pool 'org.quartz.simpl.SimpleThreadPool' - with 10 threads.
  Using job-store 'org.quartz.simpl.RAMJobStore' - which does not support persistence. and is not clustered.

2021-04-06 14:29:45.959 [main] INFO  org.quartz.impl.StdSchedulerFactory - Quartz scheduler 'quartzScheduler' initialized from an externally provided properties instance.
2021-04-06 14:29:45.959 [main] INFO  org.quartz.impl.StdSchedulerFactory - Quartz scheduler version: 2.3.2
2021-04-06 14:29:45.959 [main] INFO  org.quartz.core.QuartzScheduler - JobFactory set to: org.springframework.scheduling.quartz.SpringBeanJobFactory@da4cf09
2021-04-06 14:29:45.959 [main] INFO  org.quartz.core.QuartzScheduler - Scheduler quartzScheduler_$_NON_CLUSTERED started.
2021-04-06 14:29:45.960 [main] INFO  com.boot.kafka.config.task.SchedulerConfig - 调度器启动成功
2021-04-06 14:29:45.966 [main] INFO  com.boot.kafka.config.task.SchedulerConfig - 流任务初始化成功
2021-04-06 14:29:45.976 [quartzScheduler_Worker-1] INFO  com.boot.kafka.config.task.StreamJob - 开始启动kafka的流式操作
2021-04-06 14:29:45.994 [quartzScheduler_Worker-1] INFO  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [172.17.112.123:19192]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 3
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2021-04-06 14:29:46.010 [quartzScheduler_Worker-1] INFO  org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-1] Instantiated an idempotent producer.
2021-04-06 14:29:46.047 [quartzScheduler_Worker-1] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.0.0
2021-04-06 14:29:46.047 [quartzScheduler_Worker-1] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : 3402a8361b734732
2021-04-06 14:29:46.049 [quartzScheduler_Worker-1] INFO  com.boot.kafka.util.KafkaUtil - 等幂模式Kafka生产者初始化成功
2021-04-06 14:29:46.074 [quartzScheduler_Worker-1] INFO  org.apache.kafka.streams.StreamsConfig - StreamsConfig values: 
	application.id = test-ath
	application.server = 
	bootstrap.servers = [172.17.112.123:19192]
	buffered.records.per.partition = 1000
	cache.max.bytes.buffering = 10485760
	client.id = 
	commit.interval.ms = 30000
	connections.max.idle.ms = 540000
	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
	default.key.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
	default.value.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	num.standby.replicas = 0
	num.stream.threads = 1
	partition.grouper = class org.apache.kafka.streams.processor.DefaultPartitionGrouper
	poll.ms = 100
	processing.guarantee = at_least_once
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	replication.factor = 1
	request.timeout.ms = 40000
	retries = 0
	retry.backoff.ms = 100
	rocksdb.config.setter = null
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	state.cleanup.delay.ms = 600000
	state.dir = /tmp/kafka-streams
	topology.optimization = none
	upgrade.from = null
	windowstore.changelog.additional.retention.ms = 86400000

2021-04-06 14:29:46.089 [quartzScheduler_Worker-1] INFO  org.apache.kafka.clients.admin.AdminClientConfig - AdminClientConfig values: 
	bootstrap.servers = [172.17.112.123:19192]
	client.id = test-ath-a1f0809f-8087-4f87-a75b-19e1b0eb934b-admin
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2021-04-06 14:29:46.097 [quartzScheduler_Worker-1] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.0.0
2021-04-06 14:29:46.097 [quartzScheduler_Worker-1] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : 3402a8361b734732
2021-04-06 14:29:46.097 [quartzScheduler_Worker-1] INFO  o.a.kafka.streams.processor.internals.StreamThread - stream-thread [test-ath-a1f0809f-8087-4f87-a75b-19e1b0eb934b-StreamThread-1] Creating restore consumer client
2021-04-06 14:29:46.100 [quartzScheduler_Worker-1] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = none
	bootstrap.servers = [172.17.112.123:19192]
	check.crcs = true
	client.id = test-ath-a1f0809f-8087-4f87-a75b-19e1b0eb934b-StreamThread-1-restore-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 2147483647
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2021-04-06 14:29:46.123 [quartzScheduler_Worker-1] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.0.0
2021-04-06 14:29:46.124 [quartzScheduler_Worker-1] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : 3402a8361b734732
2021-04-06 14:29:46.125 [quartzScheduler_Worker-1] INFO  o.a.kafka.streams.processor.internals.StreamThread - stream-thread [test-ath-a1f0809f-8087-4f87-a75b-19e1b0eb934b-StreamThread-1] Creating shared producer client
2021-04-06 14:29:46.126 [quartzScheduler_Worker-1] INFO  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [172.17.112.123:19192]
	buffer.memory = 33554432
	client.id = test-ath-a1f0809f-8087-4f87-a75b-19e1b0eb934b-StreamThread-1-producer
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 100
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 10
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2021-04-06 14:29:46.130 [quartzScheduler_Worker-1] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.0.0
2021-04-06 14:29:46.130 [quartzScheduler_Worker-1] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : 3402a8361b734732
2021-04-06 14:29:46.139 [quartzScheduler_Worker-1] INFO  o.a.kafka.streams.processor.internals.StreamThread - stream-thread [test-ath-a1f0809f-8087-4f87-a75b-19e1b0eb934b-StreamThread-1] Creating consumer client
2021-04-06 14:29:46.141 [quartzScheduler_Worker-1] INFO  org.apache.kafka.clients.admin.AdminClientConfig - AdminClientConfig values: 
	bootstrap.servers = [172.17.112.123:19192]
	client.id = 
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2021-04-06 14:29:46.141 [quartzScheduler_Worker-1] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [172.17.112.123:19192]
	check.crcs = true
	client.id = test-ath-a1f0809f-8087-4f87-a75b-19e1b0eb934b-StreamThread-1-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-ath
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 2147483647
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2021-04-06 14:29:46.145 [quartzScheduler_Worker-1] INFO  org.apache.kafka.streams.StreamsConfig - StreamsConfig values: 
	application.id = test-ath
	application.server = 
	bootstrap.servers = [172.17.112.123:19192]
	buffered.records.per.partition = 1000
	cache.max.bytes.buffering = 10485760
	client.id = test-ath-a1f0809f-8087-4f87-a75b-19e1b0eb934b-StreamThread-1-consumer
	commit.interval.ms = 30000
	connections.max.idle.ms = 540000
	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
	default.key.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
	default.value.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	num.standby.replicas = 0
	num.stream.threads = 1
	partition.grouper = class org.apache.kafka.streams.processor.DefaultPartitionGrouper
	poll.ms = 100
	processing.guarantee = at_least_once
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	replication.factor = 1
	request.timeout.ms = 40000
	retries = 0
	retry.backoff.ms = 100
	rocksdb.config.setter = null
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	state.cleanup.delay.ms = 600000
	state.dir = /tmp/kafka-streams
	topology.optimization = none
	upgrade.from = null
	windowstore.changelog.additional.retention.ms = 86400000

2021-04-06 14:29:46.147 [quartzScheduler_Worker-1] INFO  org.apache.kafka.clients.admin.AdminClientConfig - AdminClientConfig values: 
	bootstrap.servers = [172.17.112.123:19192]
	client.id = dummy-admin
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2021-04-06 14:29:46.151 [quartzScheduler_Worker-1] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.0.0
2021-04-06 14:29:46.151 [quartzScheduler_Worker-1] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : 3402a8361b734732
2021-04-06 14:29:46.175 [test-ath-a1f0809f-8087-4f87-a75b-19e1b0eb934b-StreamThread-1] INFO  o.a.kafka.streams.processor.internals.StreamThread - stream-thread [test-ath-a1f0809f-8087-4f87-a75b-19e1b0eb934b-StreamThread-1] Starting
2021-04-06 14:29:46.176 [test-ath-a1f0809f-8087-4f87-a75b-19e1b0eb934b-StreamThread-1] INFO  o.a.kafka.streams.processor.internals.StreamThread - stream-thread [test-ath-a1f0809f-8087-4f87-a75b-19e1b0eb934b-StreamThread-1] State transition from CREATED to RUNNING
2021-04-06 14:29:46.176 [quartzScheduler_Worker-1] INFO  org.apache.kafka.streams.KafkaStreams - stream-client [test-ath-a1f0809f-8087-4f87-a75b-19e1b0eb934b] Started Streams client
2021-04-06 14:29:46.219 [kafka-producer-network-thread | producer-1] INFO  o.a.k.c.producer.internals.TransactionManager - [Producer clientId=producer-1] ProducerId set to 3021 with epoch 0
2021-04-06 14:29:46.223 [test-ath-a1f0809f-8087-4f87-a75b-19e1b0eb934b-StreamThread-1] INFO  org.apache.kafka.clients.Metadata - Cluster ID: cseuN2TaSe27oN-yqROAFw
2021-04-06 14:29:46.224 [test-ath-a1f0809f-8087-4f87-a75b-19e1b0eb934b-StreamThread-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=test-ath-a1f0809f-8087-4f87-a75b-19e1b0eb934b-StreamThread-1-consumer, groupId=test-ath] Discovered group coordinator 172.17.112.123:19192 (id: 2147483647 rack: null)
2021-04-06 14:29:46.271 [test-ath-a1f0809f-8087-4f87-a75b-19e1b0eb934b-StreamThread-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=test-ath-a1f0809f-8087-4f87-a75b-19e1b0eb934b-StreamThread-1-consumer, groupId=test-ath] Revoking previously assigned partitions []
2021-04-06 14:29:46.272 [test-ath-a1f0809f-8087-4f87-a75b-19e1b0eb934b-StreamThread-1] INFO  o.a.kafka.streams.processor.internals.StreamThread - stream-thread [test-ath-a1f0809f-8087-4f87-a75b-19e1b0eb934b-StreamThread-1] State transition from RUNNING to PARTITIONS_REVOKED
2021-04-06 14:29:46.273 [test-ath-a1f0809f-8087-4f87-a75b-19e1b0eb934b-StreamThread-1] INFO  org.apache.kafka.streams.KafkaStreams - stream-client [test-ath-a1f0809f-8087-4f87-a75b-19e1b0eb934b] State transition from RUNNING to REBALANCING
2021-04-06 14:29:46.274 [test-ath-a1f0809f-8087-4f87-a75b-19e1b0eb934b-StreamThread-1] INFO  o.a.kafka.streams.processor.internals.StreamThread - stream-thread [test-ath-a1f0809f-8087-4f87-a75b-19e1b0eb934b-StreamThread-1] partition revocation took 1 ms.
	suspended active tasks: []
	suspended standby tasks: []
2021-04-06 14:29:46.274 [test-ath-a1f0809f-8087-4f87-a75b-19e1b0eb934b-StreamThread-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=test-ath-a1f0809f-8087-4f87-a75b-19e1b0eb934b-StreamThread-1-consumer, groupId=test-ath] (Re-)joining group
2021-04-06 14:29:46.294 [test-ath-a1f0809f-8087-4f87-a75b-19e1b0eb934b-StreamThread-1] INFO  o.a.k.s.p.internals.StreamsPartitionAssignor - stream-thread [test-ath-a1f0809f-8087-4f87-a75b-19e1b0eb934b-StreamThread-1-consumer] Assigned tasks to clients as {a1f0809f-8087-4f87-a75b-19e1b0eb934b=[activeTasks: ([0_0, 0_1, 0_2, 0_3, 0_4, 0_5, 0_6, 0_7, 0_8, 0_9]) standbyTasks: ([]) assignedTasks: ([0_0, 0_1, 0_2, 0_3, 0_4, 0_5, 0_6, 0_7, 0_8, 0_9]) prevActiveTasks: ([]) prevStandbyTasks: ([]) prevAssignedTasks: ([]) capacity: 1]}.
2021-04-06 14:29:46.302 [test-ath-a1f0809f-8087-4f87-a75b-19e1b0eb934b-StreamThread-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=test-ath-a1f0809f-8087-4f87-a75b-19e1b0eb934b-StreamThread-1-consumer, groupId=test-ath] Successfully joined group with generation 3
2021-04-06 14:29:46.304 [test-ath-a1f0809f-8087-4f87-a75b-19e1b0eb934b-StreamThread-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=test-ath-a1f0809f-8087-4f87-a75b-19e1b0eb934b-StreamThread-1-consumer, groupId=test-ath] Setting newly assigned partitions [wiscom.test-0, wiscom.test-1, wiscom.test-6, wiscom.test-7, wiscom.test-8, wiscom.test-9, wiscom.test-2, wiscom.test-3, wiscom.test-4, wiscom.test-5]
2021-04-06 14:29:46.304 [test-ath-a1f0809f-8087-4f87-a75b-19e1b0eb934b-StreamThread-1] INFO  o.a.kafka.streams.processor.internals.StreamThread - stream-thread [test-ath-a1f0809f-8087-4f87-a75b-19e1b0eb934b-StreamThread-1] State transition from PARTITIONS_REVOKED to PARTITIONS_ASSIGNED
2021-04-06 14:29:46.324 [test-ath-a1f0809f-8087-4f87-a75b-19e1b0eb934b-StreamThread-1] INFO  o.a.kafka.streams.processor.internals.StreamThread - stream-thread [test-ath-a1f0809f-8087-4f87-a75b-19e1b0eb934b-StreamThread-1] partition assignment took 20 ms.
	current active tasks: [0_0, 0_1, 0_2, 0_3, 0_4, 0_5, 0_6, 0_7, 0_8, 0_9]
	current standby tasks: []
	previous active tasks: []

2021-04-06 14:29:46.338 [test-ath-a1f0809f-8087-4f87-a75b-19e1b0eb934b-StreamThread-1] INFO  o.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=test-ath-a1f0809f-8087-4f87-a75b-19e1b0eb934b-StreamThread-1-consumer, groupId=test-ath] Resetting offset for partition wiscom.test-0 to offset 2.
2021-04-06 14:29:46.338 [test-ath-a1f0809f-8087-4f87-a75b-19e1b0eb934b-StreamThread-1] INFO  o.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=test-ath-a1f0809f-8087-4f87-a75b-19e1b0eb934b-StreamThread-1-consumer, groupId=test-ath] Resetting offset for partition wiscom.test-1 to offset 0.
2021-04-06 14:29:46.339 [test-ath-a1f0809f-8087-4f87-a75b-19e1b0eb934b-StreamThread-1] INFO  o.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=test-ath-a1f0809f-8087-4f87-a75b-19e1b0eb934b-StreamThread-1-consumer, groupId=test-ath] Resetting offset for partition wiscom.test-6 to offset 0.
2021-04-06 14:29:46.339 [test-ath-a1f0809f-8087-4f87-a75b-19e1b0eb934b-StreamThread-1] INFO  o.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=test-ath-a1f0809f-8087-4f87-a75b-19e1b0eb934b-StreamThread-1-consumer, groupId=test-ath] Resetting offset for partition wiscom.test-7 to offset 1.
2021-04-06 14:29:46.339 [test-ath-a1f0809f-8087-4f87-a75b-19e1b0eb934b-StreamThread-1] INFO  o.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=test-ath-a1f0809f-8087-4f87-a75b-19e1b0eb934b-StreamThread-1-consumer, groupId=test-ath] Resetting offset for partition wiscom.test-8 to offset 0.
2021-04-06 14:29:46.339 [test-ath-a1f0809f-8087-4f87-a75b-19e1b0eb934b-StreamThread-1] INFO  o.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=test-ath-a1f0809f-8087-4f87-a75b-19e1b0eb934b-StreamThread-1-consumer, groupId=test-ath] Resetting offset for partition wiscom.test-9 to offset 1.
2021-04-06 14:29:46.339 [test-ath-a1f0809f-8087-4f87-a75b-19e1b0eb934b-StreamThread-1] INFO  o.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=test-ath-a1f0809f-8087-4f87-a75b-19e1b0eb934b-StreamThread-1-consumer, groupId=test-ath] Resetting offset for partition wiscom.test-2 to offset 1.
2021-04-06 14:29:46.339 [test-ath-a1f0809f-8087-4f87-a75b-19e1b0eb934b-StreamThread-1] INFO  o.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=test-ath-a1f0809f-8087-4f87-a75b-19e1b0eb934b-StreamThread-1-consumer, groupId=test-ath] Resetting offset for partition wiscom.test-3 to offset 0.
2021-04-06 14:29:46.339 [test-ath-a1f0809f-8087-4f87-a75b-19e1b0eb934b-StreamThread-1] INFO  o.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=test-ath-a1f0809f-8087-4f87-a75b-19e1b0eb934b-StreamThread-1-consumer, groupId=test-ath] Resetting offset for partition wiscom.test-4 to offset 0.
2021-04-06 14:29:46.339 [test-ath-a1f0809f-8087-4f87-a75b-19e1b0eb934b-StreamThread-1] INFO  o.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=test-ath-a1f0809f-8087-4f87-a75b-19e1b0eb934b-StreamThread-1-consumer, groupId=test-ath] Resetting offset for partition wiscom.test-5 to offset 2.
2021-04-06 14:29:46.416 [test-ath-a1f0809f-8087-4f87-a75b-19e1b0eb934b-StreamThread-1] INFO  o.a.kafka.streams.processor.internals.StreamThread - stream-thread [test-ath-a1f0809f-8087-4f87-a75b-19e1b0eb934b-StreamThread-1] State transition from PARTITIONS_ASSIGNED to RUNNING
2021-04-06 14:29:46.417 [test-ath-a1f0809f-8087-4f87-a75b-19e1b0eb934b-StreamThread-1] INFO  org.apache.kafka.streams.KafkaStreams - stream-client [test-ath-a1f0809f-8087-4f87-a75b-19e1b0eb934b] State transition from REBALANCING to RUNNING
2021-04-06 14:29:46.658 [main] INFO  o.s.scheduling.concurrent.ThreadPoolTaskExecutor - Initializing ExecutorService 'applicationTaskExecutor'
2021-04-06 14:29:46.827 [main] INFO  org.apache.coyote.http11.Http11NioProtocol - Starting ProtocolHandler ["http-nio-9200"]
2021-04-06 14:29:46.840 [main] INFO  o.s.boot.web.embedded.tomcat.TomcatWebServer - Tomcat started on port(s): 9200 (http) with context path ''
2021-04-06 14:29:47.045 [main] INFO  com.boot.kafka.KafkaApplication - Started KafkaApplication in 3.172 seconds (JVM running for 4.564)
2021-04-06 14:29:51.514 [http-nio-9200-exec-1] INFO  o.a.c.core.ContainerBase.[Tomcat].[localhost].[/] - Initializing Spring DispatcherServlet 'dispatcherServlet'
2021-04-06 14:29:51.515 [http-nio-9200-exec-1] INFO  org.springframework.web.servlet.DispatcherServlet - Initializing Servlet 'dispatcherServlet'
2021-04-06 14:29:51.517 [http-nio-9200-exec-1] INFO  org.springframework.web.servlet.DispatcherServlet - Completed initialization in 2 ms
2021-04-06 14:29:51.617 [kafka-producer-network-thread | producer-1] INFO  org.apache.kafka.clients.Metadata - Cluster ID: cseuN2TaSe27oN-yqROAFw
2021-04-06 14:29:51.645 [http-nio-9200-exec-1] INFO  com.boot.kafka.dao.ProducerDao - wiscom.test-0@2
2021-04-06 14:29:51.659 [kafka-producer-network-thread | test-ath-a1f0809f-8087-4f87-a75b-19e1b0eb934b-StreamThread-1-producer] INFO  org.apache.kafka.clients.Metadata - Cluster ID: cseuN2TaSe27oN-yqROAFw
2021-04-06 14:30:02.233 [SpringContextShutdownHook] INFO  org.quartz.core.QuartzScheduler - Scheduler quartzScheduler_$_NON_CLUSTERED paused.
2021-04-06 14:32:06.714 [main] INFO  com.boot.kafka.KafkaApplication - Starting KafkaApplication using Java 1.8.0_131 on LAPTOP-281R0H88 with PID 11744 (D:\project\code\self_util\muti-scaffold\boot-kafka\target\classes started by 月月 in D:\project\code\self_util\muti-scaffold)
2021-04-06 14:32:06.718 [main] INFO  com.boot.kafka.KafkaApplication - The following profiles are active: dev,kafka,business
2021-04-06 14:32:08.021 [main] INFO  o.s.boot.web.embedded.tomcat.TomcatWebServer - Tomcat initialized with port(s): 9200 (http)
2021-04-06 14:32:08.030 [main] INFO  org.apache.coyote.http11.Http11NioProtocol - Initializing ProtocolHandler ["http-nio-9200"]
2021-04-06 14:32:08.031 [main] INFO  org.apache.catalina.core.StandardService - Starting service [Tomcat]
2021-04-06 14:32:08.031 [main] INFO  org.apache.catalina.core.StandardEngine - Starting Servlet engine: [Apache Tomcat/9.0.43]
2021-04-06 14:32:08.126 [main] INFO  o.a.c.core.ContainerBase.[Tomcat].[localhost].[/] - Initializing Spring embedded WebApplicationContext
2021-04-06 14:32:08.127 [main] INFO  o.s.b.w.s.c.ServletWebServerApplicationContext - Root WebApplicationContext: initialization completed in 1355 ms
2021-04-06 14:32:08.188 [main] INFO  com.boot.kafka.common.GlobalObject - kafka配置读取成功
2021-04-06 14:32:08.221 [main] INFO  org.quartz.impl.StdSchedulerFactory - Using default implementation for ThreadExecutor
2021-04-06 14:32:08.234 [main] INFO  org.quartz.core.SchedulerSignalerImpl - Initialized Scheduler Signaller of type: class org.quartz.core.SchedulerSignalerImpl
2021-04-06 14:32:08.234 [main] INFO  org.quartz.core.QuartzScheduler - Quartz Scheduler v.2.3.2 created.
2021-04-06 14:32:08.235 [main] INFO  org.quartz.simpl.RAMJobStore - RAMJobStore initialized.
2021-04-06 14:32:08.236 [main] INFO  org.quartz.core.QuartzScheduler - Scheduler meta-data: Quartz Scheduler (v2.3.2) 'quartzScheduler' with instanceId 'NON_CLUSTERED'
  Scheduler class: 'org.quartz.core.QuartzScheduler' - running locally.
  NOT STARTED.
  Currently in standby mode.
  Number of jobs executed: 0
  Using thread pool 'org.quartz.simpl.SimpleThreadPool' - with 10 threads.
  Using job-store 'org.quartz.simpl.RAMJobStore' - which does not support persistence. and is not clustered.

2021-04-06 14:32:08.237 [main] INFO  org.quartz.impl.StdSchedulerFactory - Quartz scheduler 'quartzScheduler' initialized from an externally provided properties instance.
2021-04-06 14:32:08.237 [main] INFO  org.quartz.impl.StdSchedulerFactory - Quartz scheduler version: 2.3.2
2021-04-06 14:32:08.237 [main] INFO  org.quartz.core.QuartzScheduler - JobFactory set to: org.springframework.scheduling.quartz.SpringBeanJobFactory@2921a36a
2021-04-06 14:32:08.237 [main] INFO  org.quartz.core.QuartzScheduler - Scheduler quartzScheduler_$_NON_CLUSTERED started.
2021-04-06 14:32:08.238 [main] INFO  com.boot.kafka.config.task.SchedulerConfig - 调度器启动成功
2021-04-06 14:32:08.244 [main] INFO  com.boot.kafka.config.task.SchedulerConfig - 流任务初始化成功
2021-04-06 14:32:08.253 [quartzScheduler_Worker-1] INFO  com.boot.kafka.config.task.StreamJob - 开始启动kafka的流式操作
2021-04-06 14:32:08.272 [quartzScheduler_Worker-1] INFO  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [172.17.112.123:19192]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 3
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2021-04-06 14:32:08.291 [quartzScheduler_Worker-1] INFO  org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-1] Instantiated an idempotent producer.
2021-04-06 14:32:08.331 [quartzScheduler_Worker-1] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.0.0
2021-04-06 14:32:08.331 [quartzScheduler_Worker-1] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : 3402a8361b734732
2021-04-06 14:32:08.334 [quartzScheduler_Worker-1] INFO  com.boot.kafka.util.KafkaUtil - 等幂模式Kafka生产者初始化成功
2021-04-06 14:32:08.372 [quartzScheduler_Worker-1] INFO  org.apache.kafka.streams.StreamsConfig - StreamsConfig values: 
	application.id = test-ath
	application.server = 
	bootstrap.servers = [172.17.112.123:19192]
	buffered.records.per.partition = 1000
	cache.max.bytes.buffering = 10485760
	client.id = 
	commit.interval.ms = 30000
	connections.max.idle.ms = 540000
	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
	default.key.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
	default.value.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	num.standby.replicas = 0
	num.stream.threads = 1
	partition.grouper = class org.apache.kafka.streams.processor.DefaultPartitionGrouper
	poll.ms = 100
	processing.guarantee = at_least_once
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	replication.factor = 1
	request.timeout.ms = 40000
	retries = 0
	retry.backoff.ms = 100
	rocksdb.config.setter = null
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	state.cleanup.delay.ms = 600000
	state.dir = /tmp/kafka-streams
	topology.optimization = none
	upgrade.from = null
	windowstore.changelog.additional.retention.ms = 86400000

2021-04-06 14:32:08.389 [quartzScheduler_Worker-1] INFO  org.apache.kafka.clients.admin.AdminClientConfig - AdminClientConfig values: 
	bootstrap.servers = [172.17.112.123:19192]
	client.id = test-ath-90676215-ab1b-4af4-a4ba-2bdf8513eac4-admin
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2021-04-06 14:32:08.396 [quartzScheduler_Worker-1] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.0.0
2021-04-06 14:32:08.397 [quartzScheduler_Worker-1] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : 3402a8361b734732
2021-04-06 14:32:08.397 [quartzScheduler_Worker-1] INFO  o.a.kafka.streams.processor.internals.StreamThread - stream-thread [test-ath-90676215-ab1b-4af4-a4ba-2bdf8513eac4-StreamThread-1] Creating restore consumer client
2021-04-06 14:32:08.400 [quartzScheduler_Worker-1] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = none
	bootstrap.servers = [172.17.112.123:19192]
	check.crcs = true
	client.id = test-ath-90676215-ab1b-4af4-a4ba-2bdf8513eac4-StreamThread-1-restore-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 2147483647
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2021-04-06 14:32:08.426 [quartzScheduler_Worker-1] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.0.0
2021-04-06 14:32:08.426 [quartzScheduler_Worker-1] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : 3402a8361b734732
2021-04-06 14:32:08.427 [quartzScheduler_Worker-1] INFO  o.a.kafka.streams.processor.internals.StreamThread - stream-thread [test-ath-90676215-ab1b-4af4-a4ba-2bdf8513eac4-StreamThread-1] Creating shared producer client
2021-04-06 14:32:08.428 [quartzScheduler_Worker-1] INFO  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [172.17.112.123:19192]
	buffer.memory = 33554432
	client.id = test-ath-90676215-ab1b-4af4-a4ba-2bdf8513eac4-StreamThread-1-producer
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 100
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 10
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2021-04-06 14:32:08.433 [quartzScheduler_Worker-1] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.0.0
2021-04-06 14:32:08.433 [quartzScheduler_Worker-1] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : 3402a8361b734732
2021-04-06 14:32:08.445 [quartzScheduler_Worker-1] INFO  o.a.kafka.streams.processor.internals.StreamThread - stream-thread [test-ath-90676215-ab1b-4af4-a4ba-2bdf8513eac4-StreamThread-1] Creating consumer client
2021-04-06 14:32:08.447 [quartzScheduler_Worker-1] INFO  org.apache.kafka.clients.admin.AdminClientConfig - AdminClientConfig values: 
	bootstrap.servers = [172.17.112.123:19192]
	client.id = 
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2021-04-06 14:32:08.448 [quartzScheduler_Worker-1] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [172.17.112.123:19192]
	check.crcs = true
	client.id = test-ath-90676215-ab1b-4af4-a4ba-2bdf8513eac4-StreamThread-1-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-ath
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 2147483647
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2021-04-06 14:32:08.455 [quartzScheduler_Worker-1] INFO  org.apache.kafka.streams.StreamsConfig - StreamsConfig values: 
	application.id = test-ath
	application.server = 
	bootstrap.servers = [172.17.112.123:19192]
	buffered.records.per.partition = 1000
	cache.max.bytes.buffering = 10485760
	client.id = test-ath-90676215-ab1b-4af4-a4ba-2bdf8513eac4-StreamThread-1-consumer
	commit.interval.ms = 30000
	connections.max.idle.ms = 540000
	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
	default.key.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
	default.value.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	num.standby.replicas = 0
	num.stream.threads = 1
	partition.grouper = class org.apache.kafka.streams.processor.DefaultPartitionGrouper
	poll.ms = 100
	processing.guarantee = at_least_once
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	replication.factor = 1
	request.timeout.ms = 40000
	retries = 0
	retry.backoff.ms = 100
	rocksdb.config.setter = null
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	state.cleanup.delay.ms = 600000
	state.dir = /tmp/kafka-streams
	topology.optimization = none
	upgrade.from = null
	windowstore.changelog.additional.retention.ms = 86400000

2021-04-06 14:32:08.457 [quartzScheduler_Worker-1] INFO  org.apache.kafka.clients.admin.AdminClientConfig - AdminClientConfig values: 
	bootstrap.servers = [172.17.112.123:19192]
	client.id = dummy-admin
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2021-04-06 14:32:08.462 [quartzScheduler_Worker-1] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.0.0
2021-04-06 14:32:08.462 [quartzScheduler_Worker-1] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : 3402a8361b734732
2021-04-06 14:32:08.474 [quartzScheduler_Worker-1] INFO  org.apache.kafka.streams.KafkaStreams - stream-client [test-ath-90676215-ab1b-4af4-a4ba-2bdf8513eac4] Started Streams client
2021-04-06 14:32:08.473 [test-ath-90676215-ab1b-4af4-a4ba-2bdf8513eac4-StreamThread-1] INFO  o.a.kafka.streams.processor.internals.StreamThread - stream-thread [test-ath-90676215-ab1b-4af4-a4ba-2bdf8513eac4-StreamThread-1] Starting
2021-04-06 14:32:08.474 [test-ath-90676215-ab1b-4af4-a4ba-2bdf8513eac4-StreamThread-1] INFO  o.a.kafka.streams.processor.internals.StreamThread - stream-thread [test-ath-90676215-ab1b-4af4-a4ba-2bdf8513eac4-StreamThread-1] State transition from CREATED to RUNNING
2021-04-06 14:32:08.594 [kafka-producer-network-thread | producer-1] INFO  o.a.k.c.producer.internals.TransactionManager - [Producer clientId=producer-1] ProducerId set to 3022 with epoch 0
2021-04-06 14:32:08.598 [test-ath-90676215-ab1b-4af4-a4ba-2bdf8513eac4-StreamThread-1] INFO  org.apache.kafka.clients.Metadata - Cluster ID: cseuN2TaSe27oN-yqROAFw
2021-04-06 14:32:08.598 [test-ath-90676215-ab1b-4af4-a4ba-2bdf8513eac4-StreamThread-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=test-ath-90676215-ab1b-4af4-a4ba-2bdf8513eac4-StreamThread-1-consumer, groupId=test-ath] Discovered group coordinator 172.17.112.123:19192 (id: 2147483647 rack: null)
2021-04-06 14:32:08.600 [test-ath-90676215-ab1b-4af4-a4ba-2bdf8513eac4-StreamThread-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=test-ath-90676215-ab1b-4af4-a4ba-2bdf8513eac4-StreamThread-1-consumer, groupId=test-ath] Revoking previously assigned partitions []
2021-04-06 14:32:08.600 [test-ath-90676215-ab1b-4af4-a4ba-2bdf8513eac4-StreamThread-1] INFO  o.a.kafka.streams.processor.internals.StreamThread - stream-thread [test-ath-90676215-ab1b-4af4-a4ba-2bdf8513eac4-StreamThread-1] State transition from RUNNING to PARTITIONS_REVOKED
2021-04-06 14:32:08.600 [test-ath-90676215-ab1b-4af4-a4ba-2bdf8513eac4-StreamThread-1] INFO  org.apache.kafka.streams.KafkaStreams - stream-client [test-ath-90676215-ab1b-4af4-a4ba-2bdf8513eac4] State transition from RUNNING to REBALANCING
2021-04-06 14:32:08.601 [test-ath-90676215-ab1b-4af4-a4ba-2bdf8513eac4-StreamThread-1] INFO  o.a.kafka.streams.processor.internals.StreamThread - stream-thread [test-ath-90676215-ab1b-4af4-a4ba-2bdf8513eac4-StreamThread-1] partition revocation took 0 ms.
	suspended active tasks: []
	suspended standby tasks: []
2021-04-06 14:32:08.601 [test-ath-90676215-ab1b-4af4-a4ba-2bdf8513eac4-StreamThread-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=test-ath-90676215-ab1b-4af4-a4ba-2bdf8513eac4-StreamThread-1-consumer, groupId=test-ath] (Re-)joining group
2021-04-06 14:32:08.619 [test-ath-90676215-ab1b-4af4-a4ba-2bdf8513eac4-StreamThread-1] INFO  o.a.k.s.p.internals.StreamsPartitionAssignor - stream-thread [test-ath-90676215-ab1b-4af4-a4ba-2bdf8513eac4-StreamThread-1-consumer] Assigned tasks to clients as {90676215-ab1b-4af4-a4ba-2bdf8513eac4=[activeTasks: ([0_0, 0_1, 0_2, 0_3, 0_4, 0_5, 0_6, 0_7, 0_8, 0_9]) standbyTasks: ([]) assignedTasks: ([0_0, 0_1, 0_2, 0_3, 0_4, 0_5, 0_6, 0_7, 0_8, 0_9]) prevActiveTasks: ([]) prevStandbyTasks: ([]) prevAssignedTasks: ([]) capacity: 1]}.
2021-04-06 14:32:08.627 [test-ath-90676215-ab1b-4af4-a4ba-2bdf8513eac4-StreamThread-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=test-ath-90676215-ab1b-4af4-a4ba-2bdf8513eac4-StreamThread-1-consumer, groupId=test-ath] Successfully joined group with generation 5
2021-04-06 14:32:08.629 [test-ath-90676215-ab1b-4af4-a4ba-2bdf8513eac4-StreamThread-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=test-ath-90676215-ab1b-4af4-a4ba-2bdf8513eac4-StreamThread-1-consumer, groupId=test-ath] Setting newly assigned partitions [wiscom.test-0, wiscom.test-1, wiscom.test-6, wiscom.test-7, wiscom.test-8, wiscom.test-9, wiscom.test-2, wiscom.test-3, wiscom.test-4, wiscom.test-5]
2021-04-06 14:32:08.629 [test-ath-90676215-ab1b-4af4-a4ba-2bdf8513eac4-StreamThread-1] INFO  o.a.kafka.streams.processor.internals.StreamThread - stream-thread [test-ath-90676215-ab1b-4af4-a4ba-2bdf8513eac4-StreamThread-1] State transition from PARTITIONS_REVOKED to PARTITIONS_ASSIGNED
2021-04-06 14:32:08.651 [test-ath-90676215-ab1b-4af4-a4ba-2bdf8513eac4-StreamThread-1] INFO  o.a.kafka.streams.processor.internals.StreamThread - stream-thread [test-ath-90676215-ab1b-4af4-a4ba-2bdf8513eac4-StreamThread-1] partition assignment took 22 ms.
	current active tasks: [0_0, 0_1, 0_2, 0_3, 0_4, 0_5, 0_6, 0_7, 0_8, 0_9]
	current standby tasks: []
	previous active tasks: []

2021-04-06 14:32:08.669 [test-ath-90676215-ab1b-4af4-a4ba-2bdf8513eac4-StreamThread-1] INFO  o.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=test-ath-90676215-ab1b-4af4-a4ba-2bdf8513eac4-StreamThread-1-consumer, groupId=test-ath] Resetting offset for partition wiscom.test-0 to offset 3.
2021-04-06 14:32:08.669 [test-ath-90676215-ab1b-4af4-a4ba-2bdf8513eac4-StreamThread-1] INFO  o.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=test-ath-90676215-ab1b-4af4-a4ba-2bdf8513eac4-StreamThread-1-consumer, groupId=test-ath] Resetting offset for partition wiscom.test-1 to offset 0.
2021-04-06 14:32:08.670 [test-ath-90676215-ab1b-4af4-a4ba-2bdf8513eac4-StreamThread-1] INFO  o.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=test-ath-90676215-ab1b-4af4-a4ba-2bdf8513eac4-StreamThread-1-consumer, groupId=test-ath] Resetting offset for partition wiscom.test-6 to offset 0.
2021-04-06 14:32:08.670 [test-ath-90676215-ab1b-4af4-a4ba-2bdf8513eac4-StreamThread-1] INFO  o.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=test-ath-90676215-ab1b-4af4-a4ba-2bdf8513eac4-StreamThread-1-consumer, groupId=test-ath] Resetting offset for partition wiscom.test-7 to offset 1.
2021-04-06 14:32:08.670 [test-ath-90676215-ab1b-4af4-a4ba-2bdf8513eac4-StreamThread-1] INFO  o.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=test-ath-90676215-ab1b-4af4-a4ba-2bdf8513eac4-StreamThread-1-consumer, groupId=test-ath] Resetting offset for partition wiscom.test-8 to offset 0.
2021-04-06 14:32:08.670 [test-ath-90676215-ab1b-4af4-a4ba-2bdf8513eac4-StreamThread-1] INFO  o.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=test-ath-90676215-ab1b-4af4-a4ba-2bdf8513eac4-StreamThread-1-consumer, groupId=test-ath] Resetting offset for partition wiscom.test-9 to offset 1.
2021-04-06 14:32:08.670 [test-ath-90676215-ab1b-4af4-a4ba-2bdf8513eac4-StreamThread-1] INFO  o.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=test-ath-90676215-ab1b-4af4-a4ba-2bdf8513eac4-StreamThread-1-consumer, groupId=test-ath] Resetting offset for partition wiscom.test-2 to offset 1.
2021-04-06 14:32:08.670 [test-ath-90676215-ab1b-4af4-a4ba-2bdf8513eac4-StreamThread-1] INFO  o.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=test-ath-90676215-ab1b-4af4-a4ba-2bdf8513eac4-StreamThread-1-consumer, groupId=test-ath] Resetting offset for partition wiscom.test-3 to offset 0.
2021-04-06 14:32:08.670 [test-ath-90676215-ab1b-4af4-a4ba-2bdf8513eac4-StreamThread-1] INFO  o.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=test-ath-90676215-ab1b-4af4-a4ba-2bdf8513eac4-StreamThread-1-consumer, groupId=test-ath] Resetting offset for partition wiscom.test-4 to offset 0.
2021-04-06 14:32:08.670 [test-ath-90676215-ab1b-4af4-a4ba-2bdf8513eac4-StreamThread-1] INFO  o.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=test-ath-90676215-ab1b-4af4-a4ba-2bdf8513eac4-StreamThread-1-consumer, groupId=test-ath] Resetting offset for partition wiscom.test-5 to offset 2.
2021-04-06 14:32:08.731 [test-ath-90676215-ab1b-4af4-a4ba-2bdf8513eac4-StreamThread-1] INFO  o.a.kafka.streams.processor.internals.StreamThread - stream-thread [test-ath-90676215-ab1b-4af4-a4ba-2bdf8513eac4-StreamThread-1] State transition from PARTITIONS_ASSIGNED to RUNNING
2021-04-06 14:32:08.732 [test-ath-90676215-ab1b-4af4-a4ba-2bdf8513eac4-StreamThread-1] INFO  org.apache.kafka.streams.KafkaStreams - stream-client [test-ath-90676215-ab1b-4af4-a4ba-2bdf8513eac4] State transition from REBALANCING to RUNNING
2021-04-06 14:32:09.009 [main] INFO  o.s.scheduling.concurrent.ThreadPoolTaskExecutor - Initializing ExecutorService 'applicationTaskExecutor'
2021-04-06 14:32:09.191 [main] INFO  org.apache.coyote.http11.Http11NioProtocol - Starting ProtocolHandler ["http-nio-9200"]
2021-04-06 14:32:09.204 [main] INFO  o.s.boot.web.embedded.tomcat.TomcatWebServer - Tomcat started on port(s): 9200 (http) with context path ''
2021-04-06 14:32:09.443 [main] INFO  com.boot.kafka.KafkaApplication - Started KafkaApplication in 3.388 seconds (JVM running for 4.758)
2021-04-06 14:32:13.488 [http-nio-9200-exec-1] INFO  o.a.c.core.ContainerBase.[Tomcat].[localhost].[/] - Initializing Spring DispatcherServlet 'dispatcherServlet'
2021-04-06 14:32:13.488 [http-nio-9200-exec-1] INFO  org.springframework.web.servlet.DispatcherServlet - Initializing Servlet 'dispatcherServlet'
2021-04-06 14:32:13.489 [http-nio-9200-exec-1] INFO  org.springframework.web.servlet.DispatcherServlet - Completed initialization in 1 ms
2021-04-06 14:32:13.591 [kafka-producer-network-thread | producer-1] INFO  org.apache.kafka.clients.Metadata - Cluster ID: cseuN2TaSe27oN-yqROAFw
2021-04-06 14:32:13.618 [http-nio-9200-exec-1] INFO  com.boot.kafka.dao.ProducerDao - wiscom.test-0@3
2021-04-06 14:32:13.627 [kafka-producer-network-thread | test-ath-90676215-ab1b-4af4-a4ba-2bdf8513eac4-StreamThread-1-producer] INFO  org.apache.kafka.clients.Metadata - Cluster ID: cseuN2TaSe27oN-yqROAFw
2021-04-06 14:32:27.789 [SpringContextShutdownHook] INFO  org.quartz.core.QuartzScheduler - Scheduler quartzScheduler_$_NON_CLUSTERED paused.
